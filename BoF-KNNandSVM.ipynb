{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fFrEM8U8GAK",
        "outputId": "9dca7a43-14fd-430f-b437-97e57ffce452"
      },
      "source": [
        "!pip install opencv-contrib-python==3.4.2.17"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-contrib-python==3.4.2.17\n",
            "  Downloading opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.19.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.2.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeTCJ3Mc9gNb",
        "outputId": "e7c3ab27-1419-4454-e232-c9293323dfe0"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import itertools\n",
        "import time\n",
        "import zipfile\n",
        "import torch\n",
        "import torchvision\n",
        "import gc\n",
        "import pickle\n",
        "from sklearn import svm\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "print(cv2.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZNKCaUqRosp",
        "outputId": "f0471d00-c4e5-49fb-c1ed-80f156cdccdb"
      },
      "source": [
        "cd '/content/drive/MyDrive/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAJEEaWk9kRb",
        "outputId": "36337be9-df59-4458-ce25-95711440c1cd"
      },
      "source": [
        "class_names = [name[13:] for name in glob.glob('./data/train/*')]\n",
        "class_names = dict(zip(range(len(class_names)), class_names))\n",
        "print(\"class_names: %s \" % class_names)\n",
        "n_train_samples_per_class = 150\n",
        "n_test_samples_per_class = 50\n",
        "\n",
        "def load_dataset(path, num_per_class=-1):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for id, class_name in class_names.items():\n",
        "        print(\"Loading images from class: %s\" % id)\n",
        "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
        "        if num_per_class > 0:\n",
        "            img_path_class = img_path_class[:num_per_class]\n",
        "        labels.extend([id]*len(img_path_class))\n",
        "        for filename in img_path_class:\n",
        "            data.append(cv2.imread(filename, 0))\n",
        "    return data, labels\n",
        "\n",
        "# load training dataset\n",
        "#train_data, train_label = load_dataset('./data/train/')\n",
        "train_data, train_label = load_dataset('./data/train/', n_train_samples_per_class)\n",
        "n_train = len(train_label)\n",
        "print(\"n_train: %s\" % n_train)\n",
        "\n",
        "# load testing dataset\n",
        "#test_data, test_label = load_dataset('./data/test/')\n",
        "test_data, test_label = load_dataset('./data/test/', n_test_samples_per_class)\n",
        "n_test = len(test_label)\n",
        "print(\"n_test: %s\" % n_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_names: {0: 'Forest', 1: 'Industrial', 2: 'Flower', 3: 'Coast', 4: 'InsideCity', 5: 'Office', 6: 'Bedroom', 7: 'Highway', 8: 'Street', 9: 'TallBuilding', 10: 'LivingRoom', 11: 'Suburb', 12: 'OpenCountry', 13: 'Mountain', 14: 'Kitchen', 15: 'Store'} \n",
            "Loading images from class: 0\n",
            "Loading images from class: 1\n",
            "Loading images from class: 2\n",
            "Loading images from class: 3\n",
            "Loading images from class: 4\n",
            "Loading images from class: 5\n",
            "Loading images from class: 6\n",
            "Loading images from class: 7\n",
            "Loading images from class: 8\n",
            "Loading images from class: 9\n",
            "Loading images from class: 10\n",
            "Loading images from class: 11\n",
            "Loading images from class: 12\n",
            "Loading images from class: 13\n",
            "Loading images from class: 14\n",
            "Loading images from class: 15\n",
            "n_train: 2400\n",
            "Loading images from class: 0\n",
            "Loading images from class: 1\n",
            "Loading images from class: 2\n",
            "Loading images from class: 3\n",
            "Loading images from class: 4\n",
            "Loading images from class: 5\n",
            "Loading images from class: 6\n",
            "Loading images from class: 7\n",
            "Loading images from class: 8\n",
            "Loading images from class: 9\n",
            "Loading images from class: 10\n",
            "Loading images from class: 11\n",
            "Loading images from class: 12\n",
            "Loading images from class: 13\n",
            "Loading images from class: 14\n",
            "Loading images from class: 15\n",
            "n_test: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTiJXgteOsoc"
      },
      "source": [
        "# Save intermediate image data into disk\n",
        "file = open('train.pkl','wb')\n",
        "pickle.dump(train_data, file)\n",
        "pickle.dump(train_label, file)\n",
        "file.close()\n",
        "\n",
        "file = open('test.pkl','wb')\n",
        "pickle.dump(test_data, file)\n",
        "pickle.dump(test_label, file)\n",
        "file.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ayb3N9mX1el",
        "outputId": "a6fbd029-54ed-4f8d-aab4-ae800df0b449"
      },
      "source": [
        "# Load intermediate image data from disk\n",
        "file = open('train.pkl', 'rb')\n",
        "train_data = pickle.load(file)\n",
        "train_label = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "file = open('test.pkl', 'rb')\n",
        "test_data = pickle.load(file)\n",
        "test_label = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "print(len(train_data), len(train_label)) # Verify number of training samples\n",
        "print(len(test_data), len(test_label))   # Verify number of testing samples"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2400 2400\n",
            "400 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRJ0LbPX7rr"
      },
      "source": [
        "#plt.imshow(train_data[1], cmap='gray') # Verify image\n",
        "img_new_size = (240, 240)\n",
        "\n",
        "train_data = list(map(lambda x: cv2.resize(x, img_new_size), train_data))\n",
        "#print('old',train_data)\n",
        "train_data = np.stack(train_data)\n",
        "#print('new',train_data)\n",
        "train_label = np.array(train_label)\n",
        "#print('new',train_label)\n",
        "\n",
        "test_data = list(map(lambda x: cv2.resize(x, img_new_size), test_data))\n",
        "test_data = np.stack(test_data)\n",
        "test_label = np.array(test_label)\n",
        "#plt.imshow(train_data[1], cmap='gray') # Verify image\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlDny0vhYB11",
        "outputId": "4bf7b0ca-14b3-4c68-8a8e-ae18d12e0283"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mer9jadTYOhK"
      },
      "source": [
        "train_data_2 = train_data.copy()\n",
        "test_data2 = test_data.copy()\n",
        "train_label2 = train_label.copy()\n",
        "label2 = test_label.copy()\n",
        "no_of_clusters = 50\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGdcOjH1YX4W"
      },
      "source": [
        "def clustering(image_list):\n",
        "  desc_list = []\n",
        "  for img in image_list:\n",
        "    extractor = cv2.xfeatures2d.SIFT_create()\n",
        "    kp = extractor.detect(img)\n",
        "    dkp = [cv2.KeyPoint(k.pt[0], k.pt[1],k.size) for k in kp]\n",
        "    keyp, descriptors = extractor.compute(img, dkp)\n",
        "    desc_list.append(descriptors)\n",
        "    \n",
        "  desc_list=np.asarray(desc_list)\n",
        "  desc_list=np.concatenate(desc_list, axis=0)\n",
        "  #desc_list = np.sqrt(desc_list).astype(int)\n",
        "\n",
        "  \n",
        "  kmeans = MiniBatchKMeans(n_clusters=50, random_state=0).fit(desc_list)\n",
        "  \n",
        "  return kmeans\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFVlJuvkYaSD"
      },
      "source": [
        "def histogram(image_list,kmeans):\n",
        "  features = []\n",
        "  for img in image_list:\n",
        "    extractor = cv2.xfeatures2d.SIFT_create()\n",
        "    ###\n",
        "    kp = extractor.detect(img)\n",
        "    dkp = [cv2.KeyPoint(k.pt[0], k.pt[1],k.size) for k in kp]\n",
        "    keyp, descriptors = extractor.compute(img, dkp)\n",
        "    ###\n",
        "    #kp, descriptors = extractor.detectAndCompute(img,None)\n",
        "    predict_class = kmeans.predict(descriptors)\n",
        "    hist, bin_edges=np.histogram(predict_class, bins=50)\n",
        "    \n",
        "    features.append(hist)\n",
        "    \n",
        "  features=np.asarray(features)\n",
        "  return features"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWELzkzAYcr6",
        "outputId": "d2384737-67e4-4f57-87ef-ea491a891324"
      },
      "source": [
        "start = time.process_time()\n",
        "kmeans = clustering(train_data_2)\n",
        "time7 = time.process_time() - start\n",
        "print(\"Time Consumption for Clustering Features: \",time7 , \"seconds\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Consumption for Clustering Features:  338.364721468 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDOrXHelYgfr",
        "outputId": "4c912bf3-aea9-48d7-d390-09efeea92a5c"
      },
      "source": [
        "start = time.process_time()\n",
        "train_feat = histogram(train_data_2,kmeans)\n",
        "test_feat = histogram(test_data2,kmeans)\n",
        "time8 = time.process_time() - start\n",
        "print(\"Time Consumption for Histogram Generation: \",time8 , \"seconds\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Consumption for Histogram Generation:  400.881764942 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fa5ugtVcxfQ",
        "outputId": "4e33f7fa-5b11-4d66-a713-a5f560c41038"
      },
      "source": [
        "start = time.process_time()\n",
        "classifier = KNeighborsClassifier(n_neighbors=10, metric = 'minkowski', p=2)\n",
        "classifier.fit(train_feat, train_label2)\n",
        "time3 = time.process_time() - start\n",
        "\n",
        "print(\"Time Consumption in Training (Bag of SIFT Representation + Nearest Neighbor Classifer) : \",time3 , \"seconds\")\n",
        "\n",
        "start = time.process_time()\n",
        "pred2 = classifier.predict(test_feat)\n",
        "time4 = time.process_time() - start\n",
        "print(\"The Prediction accuracy of this model is {:.2f}%\".format(accuracy_score(label2,pred2)*100)) \n",
        "\n",
        "print(\"Time Consumption in Prediction (Bag of SIFT Representation + Nearest Neighbor Classifer) : \",time4 , \"seconds\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Consumption in Training (Bag of SIFT Representation + Nearest Neighbor Classifer) :  0.015419666999946458 seconds\n",
            "The Prediction accuracy of this model is 44.00%\n",
            "Time Consumption in Prediction (Bag of SIFT Representation + Nearest Neighbor Classifer) :  0.12154604700003802 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVLVVVxeyyb",
        "outputId": "eb381915-cc59-440d-e6fd-9e92b7736e5f"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "#Standardizing the histogram matrix\n",
        "train_featn = scaler.fit_transform(train_feat)\n",
        "test_featn = scaler.fit_transform(test_feat)\n",
        "\n",
        "label3 = test_label.copy()\n",
        "\n",
        "start = time.process_time()\n",
        "clf = svm.LinearSVC(random_state=0, C = 4.6)    #Using lambda = 4.6 \n",
        "clf.fit(train_featn, train_label2) \n",
        "time5 = time.process_time() - start\n",
        "print(\"Time Consumption in Training (Bag of SIFT Representation + one-vs-all SVMs) : \",time5 , \"seconds\")\n",
        "\n",
        "start = time.process_time()\n",
        "pred3 = clf.predict(test_featn)\n",
        "time6 = time.process_time() - start\n",
        "print(\"Using Lambda = 4.6\")\n",
        "print(\"The Prediction accuracy of this model is {:.2f}%\".format(accuracy_score(label3,pred3)*100)) \n",
        "print(\"Time Consumption in Prediction (Bag of SIFT Representation + one-vs-all SVMs) : \",time6 , \"seconds\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Consumption in Training (Bag of SIFT Representation + one-vs-all SVMs) :  3.6915149569999812 seconds\n",
            "Using Lambda = 4.6\n",
            "The Prediction accuracy of this model is 47.50%\n",
            "Time Consumption in Prediction (Bag of SIFT Representation + one-vs-all SVMs) :  0.0013282639999943058 seconds\n"
          ]
        }
      ]
    }
  ]
}